

##Logstash binary
/usr/share/logstash/bin/

##logstash configs
/etc/logstash/

##logstash pipline example w/filebeat locally
input {
    beats {
        port => "5043"
    }
}
# The filter part of this file is commented out to indicate that it is
# optional.
#  filter {
#        grok{
#            match => { "message" => "%{IPV4:clientip} - - \[%{HTTPDATE:log_timestamp}\] "%{DATA:method} %{DATA:target} %{DATA:a_thing} #%{DATA:more_things} %{DATA:and_even_more_things} %{DATA:got_it_from} \"%{DATA:ua_string}\""}
#        }
#        geoip{
#             source => "clientip"
#        }
#        if [continent_code]
# }
#output {
#    stdout { codec => rubydebug }
#}


##To verify your configuration, run the following command
/usr/share/logstash/bin/logstash -f first-pipeline.conf --config.test_and_exit

##If the configuration file passes the configuration test, start Logstash with the following command
/usr/share/logstash/bin/logstash -f first-pipeline.conf --config.reload.automatic


##At the data source machine, run Filebeat with the following command:
sudo /usr/share/filebeat/bin/filebeat -e -c filebeat.yml -d "publish"



##Configuring where Filebeats harvests from
/etc/filebeat/filebeat.yml

##Test Filebeats configuration file
/usr/share/filebeat/bin/filebeat -configtest -e
/usr/share/filebeat/bin/filebeat(.sh) -configtest -e

##Updating Beats plugin
{ls-binpath}/logstash-plugin update logstash-input-beats

##Suggested Apache Filter
grok {
   match => [
         "message" , "%{COMBINEDAPACHELOG}+%{GREEDYDATA:extra_fields}",
         "message" , "%{COMMONAPACHELOG}+%{GREEDYDATA:extra_fields}"
   ]
   overwrite => [ "message" ]
}
